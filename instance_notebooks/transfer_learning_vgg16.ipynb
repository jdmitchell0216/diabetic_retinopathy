{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from keras import models, optimizers, Sequential, regularizers, layers\n",
    "from keras.models import load_model, model_from_json, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Flatten, Dropout, Reshape, Dense, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import applications  \n",
    "from keras import backend as k\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2931 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size=(224, 224)\n",
    "seed = 123\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "directory = 'data/train_images/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=20) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to code below](https://riptutorial.com/keras/example/32608/transfer-learning-using-keras-and-vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = applications.VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=(224, 224, 3))\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "x = layer_dict['block2_pool'].output\n",
    "\n",
    "# Stacking a new simple convolutional network on top of it    \n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Creating new model. Please note that this is NOT a Sequential() model.\n",
    "from keras.models import Model\n",
    "custom_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "\n",
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model.layers[:7]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible that the errors I've been running into with the other transfer learning setups are arising from the line containing: Model(inputs=,outputs=).\n",
    "I've been leaving them as input and output. The first time I tried fitting this model, the training accuracy dropped throughout the first epoch. I changed input and output to plural, reran every cell, and the training accuracy steadily improved throughout epoch 1, which just finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is probably true, but it doesn't fix the problem of the model only predicting the most common class (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"VGG16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['acc'])\n",
    " \n",
    "# history = model.fit(train_features,\n",
    "#                     train_labels,\n",
    "#                     epochs=20,\n",
    "#                     batch_size=batch_size,\n",
    "#                     validation_data=(validation_features,validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Explanations for the garbage overpredictions:\n",
    "* The data needs better preprocessing to be useful\n",
    "* The imagenet weights are not appropriate for this problem space\n",
    "* Class weights need to be added in order to correct for the overpredictions\n",
    "* Over or undersampling needs to be implemented in order to correct for the overpredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_hist = custom_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(custom_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_acc = 0.51124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(vgg_model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "vgg_model = applications.VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=(224, 224, 3))\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "y = layer_dict['block5_pool'].output\n",
    "\n",
    "# Stacking a new simple convolutional network on top of it    \n",
    "# y = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(y)\n",
    "# y = MayPooling2D(pool_size=(2, 2))(y)\n",
    "y = Flatten()(y)\n",
    "y = Dense(512, activation='relu')(y)\n",
    "y = Dropout(0.5)(y)\n",
    "y = Dense(256, activation='relu')(y)\n",
    "y = Dense(5, activation='softmax')(y)\n",
    "\n",
    "custom_model2 = Model(inputs=vgg_model.input, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 27,692,869\n",
      "Trainable params: 27,692,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 block1_conv1 True\n",
      "2 block1_conv2 True\n",
      "3 block1_pool True\n",
      "4 block2_conv1 True\n",
      "5 block2_conv2 True\n",
      "6 block2_pool True\n",
      "7 block3_conv1 True\n",
      "8 block3_conv2 True\n",
      "9 block3_conv3 True\n",
      "10 block3_pool True\n",
      "11 block4_conv1 True\n",
      "12 block4_conv2 True\n",
      "13 block4_conv3 True\n",
      "14 block4_pool True\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n",
      "19 flatten_1 True\n",
      "20 dense_1 True\n",
      "21 dropout_1 True\n",
      "22 dense_2 True\n",
      "23 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(custom_model2.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model2.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 block5_conv1 False\n",
      "16 block5_conv2 False\n",
      "17 block5_conv3 False\n",
      "18 block5_pool False\n",
      "19 flatten_1 True\n",
      "20 dense_1 True\n",
      "21 dropout_1 True\n",
      "22 dense_2 True\n",
      "23 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(custom_model2.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model2.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"VGG16_2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model includes all VGG16 layers besides the top. Additionally, an extra FC layer has been added and the first FC layer has been changed from 256 to 512 nodes, with the second FC layer having 256. This model does not seem to be experiencing the same problems as the previous VGG16 model. Namely, it is not only predicting the most common class (0). This could be due to either utilizing all of the VGG16 layers instead of just the first 7 or it could be due to the increased complexity in the FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_hist2 = custom_model2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_acc = 0.71814"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = applications.VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=(224, 224, 3))\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "z = layer_dict['block5_pool'].output\n",
    "\n",
    "# Stacking a new simple convolutional network on top of it    \n",
    "# z = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(z)\n",
    "# z = MayPooling2D(pool_size=(2, 2))(z)\n",
    "z = Flatten()(z)\n",
    "z = Dense(512, activation='relu')(z)\n",
    "z = Dropout(0.5)(z)\n",
    "z = Dense(512, activation='relu')(z)\n",
    "z = Dense(5, activation='softmax')(z)\n",
    "\n",
    "custom_model3 = Model(inputs=vgg_model.input, outputs=z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accidentally saved this model as custom_model2 so that variable is overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(custom_model3.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model3.layers[:19]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(custom_model3.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model3.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"VGG16_3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 3: This model is the same as custom_model2 except the FC layers have doubled in nodes to see added complexity's effect on accuracy.\n",
    "\n",
    "Version 3.1: The original version 3 levelled off at 29% accuracy. I reran it with 512 nodes in both FC layers instead of the 1024 and 512 nodes used in the original version 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_hist3 = custom_model3.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val_acc = 0.71964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = applications.VGG16(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=(224, 224, 3))\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "x1 = layer_dict['block4_pool'].output\n",
    "\n",
    "# Stacking a new simple convolutional network on top of it    \n",
    "# x1 = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x1)\n",
    "# x1 = MayPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dropout(0.5)(x1)\n",
    "x1 = Dense(128, activation='relu')(x1)\n",
    "x1 = Dense(5, activation='softmax')(x1)\n",
    "\n",
    "custom_model4 = Model(inputs=vgg_model.input, outputs=x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 33,392,709\n",
      "Trainable params: 25,757,445\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 flatten_1 True\n",
      "16 dense_1 True\n",
      "17 dropout_1 True\n",
      "18 dense_2 True\n",
      "19 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(custom_model4.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model4.layers[:15]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_pool False\n",
      "11 block4_conv1 False\n",
      "12 block4_conv2 False\n",
      "13 block4_conv3 False\n",
      "14 block4_pool False\n",
      "15 flatten_1 True\n",
      "16 dense_1 True\n",
      "17 dropout_1 True\n",
      "18 dense_2 True\n",
      "19 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(custom_model4.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model4.compile(loss='categorical_crossentropy',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"VGG16_4.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "tensorboard = TensorBoard()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 4: This model is the same as version 3 except block 5 has been removed and FC complexity has been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 934s 21s/step - loss: 8.2430 - acc: 0.4886 - val_loss: 8.2161 - val_acc: 0.4903\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49025, saving model to VGG16_4.h5\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 893s 20s/step - loss: 8.2025 - acc: 0.4911 - val_loss: 8.0711 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.49025 to 0.49925, saving model to VGG16_4.h5\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 896s 20s/step - loss: 7.8597 - acc: 0.5124 - val_loss: 8.1678 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49925\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 892s 20s/step - loss: 8.1787 - acc: 0.4926 - val_loss: 8.3611 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.49925\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 889s 20s/step - loss: 8.2430 - acc: 0.4886 - val_loss: 7.9020 - val_acc: 0.5097\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.49925 to 0.50975, saving model to VGG16_4.h5\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 898s 20s/step - loss: 8.3130 - acc: 0.4842 - val_loss: 8.3369 - val_acc: 0.4828\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.50975\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 890s 20s/step - loss: 8.2179 - acc: 0.4901 - val_loss: 8.3369 - val_acc: 0.4828\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.50975\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 891s 20s/step - loss: 8.1829 - acc: 0.4923 - val_loss: 7.9986 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50975\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 890s 20s/step - loss: 8.2836 - acc: 0.4861 - val_loss: 7.9503 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50975\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 894s 20s/step - loss: 7.9184 - acc: 0.5087 - val_loss: 8.2886 - val_acc: 0.4858\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50975\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 909s 20s/step - loss: 8.3214 - acc: 0.4837 - val_loss: 8.1277 - val_acc: 0.4957\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.50975\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 890s 20s/step - loss: 8.1703 - acc: 0.4931 - val_loss: 8.1436 - val_acc: 0.4948\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.50975\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 893s 20s/step - loss: 8.1731 - acc: 0.4929 - val_loss: 8.2403 - val_acc: 0.4888\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.50975\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 891s 20s/step - loss: 8.1213 - acc: 0.4961 - val_loss: 8.1678 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.50975\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 889s 20s/step - loss: 8.2305 - acc: 0.4894 - val_loss: 7.9986 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.50975\n",
      "Epoch 00015: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_hist4 = custom_model4.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
