{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 and New Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying ResNet50 with same preprocessing as baseline simple CNN for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from keras import models, optimizers, Sequential, regularizers, layers\n",
    "from keras.models import load_model, model_from_json, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import resnet50\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Flatten, Dropout, Reshape, Dense, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import applications  \n",
    "from keras import backend as k\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.input_layer.InputLayer object at 0x7f324c3650b8>\n",
      "1 <keras.layers.convolutional.ZeroPadding2D object at 0x7f31c8803e10>\n",
      "2 <keras.layers.convolutional.Conv2D object at 0x7f31c8803da0>\n",
      "3 <keras.layers.normalization.BatchNormalization object at 0x7f31c8812470>\n",
      "4 <keras.layers.core.Activation object at 0x7f31c8812080>\n",
      "5 <keras.layers.convolutional.ZeroPadding2D object at 0x7f31c868c5f8>\n",
      "6 <keras.layers.pooling.MaxPooling2D object at 0x7f31c86a2ef0>\n",
      "7 <keras.layers.convolutional.Conv2D object at 0x7f31c8788a90>\n",
      "8 <keras.layers.normalization.BatchNormalization object at 0x7f31c85e5d68>\n",
      "9 <keras.layers.core.Activation object at 0x7f31c85e5f98>\n",
      "10 <keras.layers.convolutional.Conv2D object at 0x7f31c8608e80>\n",
      "11 <keras.layers.normalization.BatchNormalization object at 0x7f31c8587588>\n",
      "12 <keras.layers.core.Activation object at 0x7f31c8587c18>\n",
      "13 <keras.layers.convolutional.Conv2D object at 0x7f31c84d65f8>\n",
      "14 <keras.layers.convolutional.Conv2D object at 0x7f31c8407518>\n",
      "15 <keras.layers.normalization.BatchNormalization object at 0x7f31c83a0cc0>\n",
      "16 <keras.layers.normalization.BatchNormalization object at 0x7f31c832d400>\n",
      "17 <keras.layers.merge.Add object at 0x7f31c82fb828>\n",
      "18 <keras.layers.core.Activation object at 0x7f31c829eac8>\n",
      "19 <keras.layers.convolutional.Conv2D object at 0x7f31c829ec18>\n",
      "20 <keras.layers.normalization.BatchNormalization object at 0x7f31c8183cc0>\n",
      "21 <keras.layers.core.Activation object at 0x7f31c812e7b8>\n",
      "22 <keras.layers.convolutional.Conv2D object at 0x7f31c80f0278>\n",
      "23 <keras.layers.normalization.BatchNormalization object at 0x7f31c804e588>\n",
      "24 <keras.layers.core.Activation object at 0x7f31c8089f98>\n",
      "25 <keras.layers.convolutional.Conv2D object at 0x7f31c077c6a0>\n",
      "26 <keras.layers.normalization.BatchNormalization object at 0x7f31c06da860>\n",
      "27 <keras.layers.merge.Add object at 0x7f31c0710ac8>\n",
      "28 <keras.layers.core.Activation object at 0x7f31c06ad6a0>\n",
      "29 <keras.layers.convolutional.Conv2D object at 0x7f31c060e588>\n",
      "30 <keras.layers.normalization.BatchNormalization object at 0x7f31c05c3fd0>\n",
      "31 <keras.layers.core.Activation object at 0x7f31c0585da0>\n",
      "32 <keras.layers.convolutional.Conv2D object at 0x7f31c0575c50>\n",
      "33 <keras.layers.normalization.BatchNormalization object at 0x7f31c0439f60>\n",
      "34 <keras.layers.core.Activation object at 0x7f31c049c780>\n",
      "35 <keras.layers.convolutional.Conv2D object at 0x7f31c03ebc50>\n",
      "36 <keras.layers.normalization.BatchNormalization object at 0x7f31c03c3b70>\n",
      "37 <keras.layers.merge.Add object at 0x7f31c038e160>\n",
      "38 <keras.layers.core.Activation object at 0x7f31c02db048>\n",
      "39 <keras.layers.convolutional.Conv2D object at 0x7f31c02db7b8>\n",
      "40 <keras.layers.normalization.BatchNormalization object at 0x7f31c02383c8>\n",
      "41 <keras.layers.core.Activation object at 0x7f31c02385c0>\n",
      "42 <keras.layers.convolutional.Conv2D object at 0x7f31c0185748>\n",
      "43 <keras.layers.normalization.BatchNormalization object at 0x7f31c016a2e8>\n",
      "44 <keras.layers.core.Activation object at 0x7f31c011ecc0>\n",
      "45 <keras.layers.convolutional.Conv2D object at 0x7f31a87d87b8>\n",
      "46 <keras.layers.convolutional.Conv2D object at 0x7f31a873c828>\n",
      "47 <keras.layers.normalization.BatchNormalization object at 0x7f31c0071ef0>\n",
      "48 <keras.layers.normalization.BatchNormalization object at 0x7f31a86de3c8>\n",
      "49 <keras.layers.merge.Add object at 0x7f31a86ac7f0>\n",
      "50 <keras.layers.core.Activation object at 0x7f31a85903c8>\n",
      "51 <keras.layers.convolutional.Conv2D object at 0x7f31a85137f0>\n",
      "52 <keras.layers.normalization.BatchNormalization object at 0x7f31a8538fd0>\n",
      "53 <keras.layers.core.Activation object at 0x7f31a84dd208>\n",
      "54 <keras.layers.convolutional.Conv2D object at 0x7f31a84a3390>\n",
      "55 <keras.layers.normalization.BatchNormalization object at 0x7f31a8384550>\n",
      "56 <keras.layers.core.Activation object at 0x7f31a83becc0>\n",
      "57 <keras.layers.convolutional.Conv2D object at 0x7f31a829d1d0>\n",
      "58 <keras.layers.normalization.BatchNormalization object at 0x7f31a83765c0>\n",
      "59 <keras.layers.merge.Add object at 0x7f31a83385c0>\n",
      "60 <keras.layers.core.Activation object at 0x7f31a820bcf8>\n",
      "61 <keras.layers.convolutional.Conv2D object at 0x7f31a820b6d8>\n",
      "62 <keras.layers.normalization.BatchNormalization object at 0x7f31a8165b00>\n",
      "63 <keras.layers.core.Activation object at 0x7f31a8165748>\n",
      "64 <keras.layers.convolutional.Conv2D object at 0x7f31a80d5c50>\n",
      "65 <keras.layers.normalization.BatchNormalization object at 0x7f31787d5f28>\n",
      "66 <keras.layers.core.Activation object at 0x7f31787ba748>\n",
      "67 <keras.layers.convolutional.Conv2D object at 0x7f3178742400>\n",
      "68 <keras.layers.normalization.BatchNormalization object at 0x7f317875db38>\n",
      "69 <keras.layers.merge.Add object at 0x7f3178729128>\n",
      "70 <keras.layers.core.Activation object at 0x7f3178675320>\n",
      "71 <keras.layers.convolutional.Conv2D object at 0x7f3178675748>\n",
      "72 <keras.layers.normalization.BatchNormalization object at 0x7f3178555588>\n",
      "73 <keras.layers.core.Activation object at 0x7f31785551d0>\n",
      "74 <keras.layers.convolutional.Conv2D object at 0x7f31785264a8>\n",
      "75 <keras.layers.normalization.BatchNormalization object at 0x7f31784892e8>\n",
      "76 <keras.layers.core.Activation object at 0x7f3178440e80>\n",
      "77 <keras.layers.convolutional.Conv2D object at 0x7f31783dce80>\n",
      "78 <keras.layers.normalization.BatchNormalization object at 0x7f31783b2588>\n",
      "79 <keras.layers.merge.Add object at 0x7f317831a7b8>\n",
      "80 <keras.layers.core.Activation object at 0x7f3178266a20>\n",
      "81 <keras.layers.convolutional.Conv2D object at 0x7f317823c438>\n",
      "82 <keras.layers.normalization.BatchNormalization object at 0x7f31781cb7b8>\n",
      "83 <keras.layers.core.Activation object at 0x7f31781b5898>\n",
      "84 <keras.layers.convolutional.Conv2D object at 0x7f31781515f8>\n",
      "85 <keras.layers.normalization.BatchNormalization object at 0x7f317816ccf8>\n",
      "86 <keras.layers.core.Activation object at 0x7f31780ba2b0>\n",
      "87 <keras.layers.convolutional.Conv2D object at 0x7f3159fcb438>\n",
      "88 <keras.layers.convolutional.Conv2D object at 0x7f3159f4f160>\n",
      "89 <keras.layers.normalization.BatchNormalization object at 0x7f3159f28588>\n",
      "90 <keras.layers.normalization.BatchNormalization object at 0x7f3159dff3c8>\n",
      "91 <keras.layers.merge.Add object at 0x7f3159e592e8>\n",
      "92 <keras.layers.core.Activation object at 0x7f3159d64390>\n",
      "93 <keras.layers.convolutional.Conv2D object at 0x7f3159ce4a58>\n",
      "94 <keras.layers.normalization.BatchNormalization object at 0x7f3159ca9588>\n",
      "95 <keras.layers.core.Activation object at 0x7f3159ca91d0>\n",
      "96 <keras.layers.convolutional.Conv2D object at 0x7f3159c7a4e0>\n",
      "97 <keras.layers.normalization.BatchNormalization object at 0x7f3159bdd2e8>\n",
      "98 <keras.layers.core.Activation object at 0x7f3159b92c88>\n",
      "99 <keras.layers.convolutional.Conv2D object at 0x7f3159b2e7f0>\n",
      "100 <keras.layers.normalization.BatchNormalization object at 0x7f3159a6b518>\n",
      "101 <keras.layers.merge.Add object at 0x7f3159aa96d8>\n",
      "102 <keras.layers.core.Activation object at 0x7f31599903c8>\n",
      "103 <keras.layers.convolutional.Conv2D object at 0x7f31599d7438>\n",
      "104 <keras.layers.normalization.BatchNormalization object at 0x7f31598d6390>\n",
      "105 <keras.layers.core.Activation object at 0x7f31598d6588>\n",
      "106 <keras.layers.convolutional.Conv2D object at 0x7f31598a7710>\n",
      "107 <keras.layers.normalization.BatchNormalization object at 0x7f3159784a20>\n",
      "108 <keras.layers.core.Activation object at 0x7f31597c0cc0>\n",
      "109 <keras.layers.convolutional.Conv2D object at 0x7f315975c7b8>\n",
      "110 <keras.layers.normalization.BatchNormalization object at 0x7f315969c7b8>\n",
      "111 <keras.layers.merge.Add object at 0x7f31596d8630>\n",
      "112 <keras.layers.core.Activation object at 0x7f31595bf860>\n",
      "113 <keras.layers.convolutional.Conv2D object at 0x7f315953fa20>\n",
      "114 <keras.layers.normalization.BatchNormalization object at 0x7f3159504550>\n",
      "115 <keras.layers.core.Activation object at 0x7f3159504198>\n",
      "116 <keras.layers.convolutional.Conv2D object at 0x7f31594d6b38>\n",
      "117 <keras.layers.normalization.BatchNormalization object at 0x7f31594b9c50>\n",
      "118 <keras.layers.core.Activation object at 0x7f315946fe80>\n",
      "119 <keras.layers.convolutional.Conv2D object at 0x7f315938b780>\n",
      "120 <keras.layers.normalization.BatchNormalization object at 0x7f3159309470>\n",
      "121 <keras.layers.merge.Add object at 0x7f31592e2c18>\n",
      "122 <keras.layers.core.Activation object at 0x7f3159250c50>\n",
      "123 <keras.layers.convolutional.Conv2D object at 0x7f315926e358>\n",
      "124 <keras.layers.normalization.BatchNormalization object at 0x7f31591ed9e8>\n",
      "125 <keras.layers.core.Activation object at 0x7f31591b56d8>\n",
      "126 <keras.layers.convolutional.Conv2D object at 0x7f31591066a0>\n",
      "127 <keras.layers.normalization.BatchNormalization object at 0x7f315909dbe0>\n",
      "128 <keras.layers.core.Activation object at 0x7f315908e320>\n",
      "129 <keras.layers.convolutional.Conv2D object at 0x7f3158fce438>\n",
      "130 <keras.layers.normalization.BatchNormalization object at 0x7f3158f924e0>\n",
      "131 <keras.layers.merge.Add object at 0x7f3158f76748>\n",
      "132 <keras.layers.core.Activation object at 0x7f3158edffd0>\n",
      "133 <keras.layers.convolutional.Conv2D object at 0x7f3158edf390>\n",
      "134 <keras.layers.normalization.BatchNormalization object at 0x7f3158deb518>\n",
      "135 <keras.layers.core.Activation object at 0x7f3158deb160>\n",
      "136 <keras.layers.convolutional.Conv2D object at 0x7f3158db3400>\n",
      "137 <keras.layers.normalization.BatchNormalization object at 0x7f3158ccabe0>\n",
      "138 <keras.layers.core.Activation object at 0x7f3158d3b320>\n",
      "139 <keras.layers.convolutional.Conv2D object at 0x7f3158c67710>\n",
      "140 <keras.layers.normalization.BatchNormalization object at 0x7f3158bbe518>\n",
      "141 <keras.layers.merge.Add object at 0x7f3158ba7710>\n",
      "142 <keras.layers.core.Activation object at 0x7f3158b109b0>\n",
      "143 <keras.layers.convolutional.Conv2D object at 0x7f3158b10b00>\n",
      "144 <keras.layers.normalization.BatchNormalization object at 0x7f3158a1a4a8>\n",
      "145 <keras.layers.core.Activation object at 0x7f3158cf5860>\n",
      "146 <keras.layers.convolutional.Conv2D object at 0x7f31589e2b38>\n",
      "147 <keras.layers.normalization.BatchNormalization object at 0x7f3158943208>\n",
      "148 <keras.layers.core.Activation object at 0x7f315897abe0>\n",
      "149 <keras.layers.convolutional.Conv2D object at 0x7f3158893dd8>\n",
      "150 <keras.layers.convolutional.Conv2D object at 0x7f3158826e80>\n",
      "151 <keras.layers.normalization.BatchNormalization object at 0x7f31588764a8>\n",
      "152 <keras.layers.normalization.BatchNormalization object at 0x7f31586c6898>\n",
      "153 <keras.layers.merge.Add object at 0x7f3158720d68>\n",
      "154 <keras.layers.core.Activation object at 0x7f315860e4e0>\n",
      "155 <keras.layers.convolutional.Conv2D object at 0x7f315860e668>\n",
      "156 <keras.layers.normalization.BatchNormalization object at 0x7f31585719e8>\n",
      "157 <keras.layers.core.Activation object at 0x7f3158571630>\n",
      "158 <keras.layers.convolutional.Conv2D object at 0x7f31584c3ac8>\n",
      "159 <keras.layers.normalization.BatchNormalization object at 0x7f315849dc88>\n",
      "160 <keras.layers.core.Activation object at 0x7f31584456d8>\n",
      "161 <keras.layers.convolutional.Conv2D object at 0x7f31583ef5c0>\n",
      "162 <keras.layers.normalization.BatchNormalization object at 0x7f315827c1d0>\n",
      "163 <keras.layers.merge.Add object at 0x7f3158334940>\n",
      "164 <keras.layers.core.Activation object at 0x7f315823e080>\n",
      "165 <keras.layers.convolutional.Conv2D object at 0x7f315823e518>\n",
      "166 <keras.layers.normalization.BatchNormalization object at 0x7f31581d79e8>\n",
      "167 <keras.layers.core.Activation object at 0x7f315819fc50>\n",
      "168 <keras.layers.convolutional.Conv2D object at 0x7f3158175f28>\n",
      "169 <keras.layers.normalization.BatchNormalization object at 0x7f31580cdc50>\n",
      "170 <keras.layers.core.Activation object at 0x7f31580b3630>\n",
      "171 <keras.layers.convolutional.Conv2D object at 0x7f3143fe1c18>\n",
      "172 <keras.layers.normalization.BatchNormalization object at 0x7f3143ef1198>\n",
      "173 <keras.layers.merge.Add object at 0x7f3143f2a8d0>\n",
      "174 <keras.layers.core.Activation object at 0x7f3143eb5128>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3662 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_all = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "        directory, \n",
    "        target_size=(224, 224), \n",
    "        batch_size = 3662, \n",
    "        seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size=0.20, random_state=123, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.20, random_state=123, stratify = y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = base_model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 conv1_pad False\n",
      "2 conv1 False\n",
      "3 bn_conv1 False\n",
      "4 activation_1 False\n",
      "5 pool1_pad False\n",
      "6 max_pooling2d_1 False\n",
      "7 res2a_branch2a False\n",
      "8 bn2a_branch2a False\n",
      "9 activation_2 False\n",
      "10 res2a_branch2b False\n",
      "11 bn2a_branch2b False\n",
      "12 activation_3 False\n",
      "13 res2a_branch2c False\n",
      "14 res2a_branch1 False\n",
      "15 bn2a_branch2c False\n",
      "16 bn2a_branch1 False\n",
      "17 add_1 False\n",
      "18 activation_4 False\n",
      "19 res2b_branch2a False\n",
      "20 bn2b_branch2a False\n",
      "21 activation_5 False\n",
      "22 res2b_branch2b False\n",
      "23 bn2b_branch2b False\n",
      "24 activation_6 False\n",
      "25 res2b_branch2c False\n",
      "26 bn2b_branch2c False\n",
      "27 add_2 False\n",
      "28 activation_7 False\n",
      "29 res2c_branch2a False\n",
      "30 bn2c_branch2a False\n",
      "31 activation_8 False\n",
      "32 res2c_branch2b False\n",
      "33 bn2c_branch2b False\n",
      "34 activation_9 False\n",
      "35 res2c_branch2c False\n",
      "36 bn2c_branch2c False\n",
      "37 add_3 False\n",
      "38 activation_10 False\n",
      "39 res3a_branch2a False\n",
      "40 bn3a_branch2a False\n",
      "41 activation_11 False\n",
      "42 res3a_branch2b False\n",
      "43 bn3a_branch2b False\n",
      "44 activation_12 False\n",
      "45 res3a_branch2c False\n",
      "46 res3a_branch1 False\n",
      "47 bn3a_branch2c False\n",
      "48 bn3a_branch1 False\n",
      "49 add_4 False\n",
      "50 activation_13 False\n",
      "51 res3b_branch2a False\n",
      "52 bn3b_branch2a False\n",
      "53 activation_14 False\n",
      "54 res3b_branch2b False\n",
      "55 bn3b_branch2b False\n",
      "56 activation_15 False\n",
      "57 res3b_branch2c False\n",
      "58 bn3b_branch2c False\n",
      "59 add_5 False\n",
      "60 activation_16 False\n",
      "61 res3c_branch2a False\n",
      "62 bn3c_branch2a False\n",
      "63 activation_17 False\n",
      "64 res3c_branch2b False\n",
      "65 bn3c_branch2b False\n",
      "66 activation_18 False\n",
      "67 res3c_branch2c False\n",
      "68 bn3c_branch2c False\n",
      "69 add_6 False\n",
      "70 activation_19 False\n",
      "71 res3d_branch2a False\n",
      "72 bn3d_branch2a False\n",
      "73 activation_20 False\n",
      "74 res3d_branch2b False\n",
      "75 bn3d_branch2b False\n",
      "76 activation_21 False\n",
      "77 res3d_branch2c False\n",
      "78 bn3d_branch2c False\n",
      "79 add_7 False\n",
      "80 activation_22 False\n",
      "81 res4a_branch2a False\n",
      "82 bn4a_branch2a False\n",
      "83 activation_23 False\n",
      "84 res4a_branch2b False\n",
      "85 bn4a_branch2b False\n",
      "86 activation_24 False\n",
      "87 res4a_branch2c False\n",
      "88 res4a_branch1 False\n",
      "89 bn4a_branch2c False\n",
      "90 bn4a_branch1 False\n",
      "91 add_8 False\n",
      "92 activation_25 False\n",
      "93 res4b_branch2a False\n",
      "94 bn4b_branch2a False\n",
      "95 activation_26 False\n",
      "96 res4b_branch2b False\n",
      "97 bn4b_branch2b False\n",
      "98 activation_27 False\n",
      "99 res4b_branch2c False\n",
      "100 bn4b_branch2c False\n",
      "101 add_9 False\n",
      "102 activation_28 False\n",
      "103 res4c_branch2a False\n",
      "104 bn4c_branch2a False\n",
      "105 activation_29 False\n",
      "106 res4c_branch2b False\n",
      "107 bn4c_branch2b False\n",
      "108 activation_30 False\n",
      "109 res4c_branch2c False\n",
      "110 bn4c_branch2c False\n",
      "111 add_10 False\n",
      "112 activation_31 False\n",
      "113 res4d_branch2a False\n",
      "114 bn4d_branch2a False\n",
      "115 activation_32 False\n",
      "116 res4d_branch2b False\n",
      "117 bn4d_branch2b False\n",
      "118 activation_33 False\n",
      "119 res4d_branch2c False\n",
      "120 bn4d_branch2c False\n",
      "121 add_11 False\n",
      "122 activation_34 False\n",
      "123 res4e_branch2a False\n",
      "124 bn4e_branch2a False\n",
      "125 activation_35 False\n",
      "126 res4e_branch2b False\n",
      "127 bn4e_branch2b False\n",
      "128 activation_36 False\n",
      "129 res4e_branch2c False\n",
      "130 bn4e_branch2c False\n",
      "131 add_12 False\n",
      "132 activation_37 False\n",
      "133 res4f_branch2a False\n",
      "134 bn4f_branch2a False\n",
      "135 activation_38 False\n",
      "136 res4f_branch2b False\n",
      "137 bn4f_branch2b False\n",
      "138 activation_39 False\n",
      "139 res4f_branch2c False\n",
      "140 bn4f_branch2c False\n",
      "141 add_13 False\n",
      "142 activation_40 False\n",
      "143 res5a_branch2a False\n",
      "144 bn5a_branch2a False\n",
      "145 activation_41 False\n",
      "146 res5a_branch2b False\n",
      "147 bn5a_branch2b False\n",
      "148 activation_42 False\n",
      "149 res5a_branch2c False\n",
      "150 res5a_branch1 False\n",
      "151 bn5a_branch2c False\n",
      "152 bn5a_branch1 False\n",
      "153 add_14 False\n",
      "154 activation_43 False\n",
      "155 res5b_branch2a False\n",
      "156 bn5b_branch2a False\n",
      "157 activation_44 False\n",
      "158 res5b_branch2b False\n",
      "159 bn5b_branch2b False\n",
      "160 activation_45 False\n",
      "161 res5b_branch2c False\n",
      "162 bn5b_branch2c False\n",
      "163 add_15 False\n",
      "164 activation_46 False\n",
      "165 res5c_branch2a False\n",
      "166 bn5c_branch2a False\n",
      "167 activation_47 False\n",
      "168 res5c_branch2b False\n",
      "169 bn5c_branch2b False\n",
      "170 activation_48 False\n",
      "171 res5c_branch2c False\n",
      "172 bn5c_branch2c False\n",
      "173 add_16 False\n",
      "174 activation_49 False\n",
      "175 flatten_1 True\n",
      "176 dense_1 True\n",
      "177 dropout_1 True\n",
      "178 dense_2 True\n",
      "179 dense_3 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 386s 165ms/step - loss: 0.0366 - acc: 0.9902 - val_loss: 1.6707 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49317, saving model to resnet50_1.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 382s 163ms/step - loss: 0.0348 - acc: 0.9915 - val_loss: 1.6739 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49317\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 379s 162ms/step - loss: 0.0382 - acc: 0.9906 - val_loss: 1.6758 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49317\n",
      "Epoch 4/40\n",
      " 640/2343 [=======>......................] - ETA: 3:33 - loss: 0.0278 - acc: 0.9922"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4fc12b9e9420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist = model_final.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "#     print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_ = confusion_matrix(y_test.argmax(axis = 1), model_final.predict(X_test).argmax(axis=1))\n",
    "classes_ = ['0','1','2','3','4']\n",
    "plot_confusion_matrix(cm_, classes = classes_, normalize=False,\n",
    "                      title='Non-normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        59\n",
      "           1       0.00      0.00      0.00        74\n",
      "           2       0.00      0.00      0.00        39\n",
      "           3       0.00      0.00      0.00       200\n",
      "           4       0.49      1.00      0.66       361\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       733\n",
      "   macro avg       0.10      0.20      0.13       733\n",
      "weighted avg       0.24      0.49      0.33       733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),model_final.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "#saving the model and its weights\n",
    "\n",
    "model_json = model_final.to_json()\n",
    "with open(\"model_resnet50_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final.save_weights(\"model_resnet50_1_weights.h5\")\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Adam optimizer\n",
    "\n",
    "Forgot to enter the validation data during the first fitting. After entering the validation data, the validation accuracy remained constant throughout fitting. Going to try Adam optimizer below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final2 = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 408s 174ms/step - loss: 5.8480 - acc: 0.6206 - val_loss: 8.1691 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49317, saving model to resnet50_2.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 400s 171ms/step - loss: 4.9151 - acc: 0.6944 - val_loss: 8.1691 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49317\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 396s 169ms/step - loss: 5.5478 - acc: 0.6551 - val_loss: 8.1691 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49317\n",
      "Epoch 4/40\n",
      " 128/2343 [>.............................] - ETA: 5:02 - loss: 4.5332 - acc: 0.7188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dab389b7378d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist2 = model_final2.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using to_categorical\n",
    "\n",
    "The validation accuracy has been stuck at 0.49317 because it's just predicting the most frequently occurring class every time. One answer after some googling suggests that using to_categorical may fix this, as the problem could be originating from an error in comparing against the y matrices.\n",
    "\n",
    "Although, if the above is true, why is the training accuracy changing? It should be categorical already...\n",
    "\n",
    "Use weights for balancing the target classes if this doesn't fix the stuck accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final3 = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 392s 167ms/step - loss: 9.8712 - acc: 0.3453 - val_loss: 3.9761 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49317, saving model to resnet50_3.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 391s 167ms/step - loss: 4.2093 - acc: 0.7247 - val_loss: 3.4970 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49317\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 389s 166ms/step - loss: 4.0529 - acc: 0.7358 - val_loss: 3.2725 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49317\n",
      "Epoch 4/40\n",
      "2343/2343 [==============================] - 387s 165ms/step - loss: 2.7864 - acc: 0.7187 - val_loss: 1.9380 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.49317\n",
      "Epoch 5/40\n",
      "2343/2343 [==============================] - 387s 165ms/step - loss: 0.8128 - acc: 0.7550 - val_loss: 1.4317 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49317\n",
      "Epoch 6/40\n",
      "2343/2343 [==============================] - 390s 166ms/step - loss: 0.5152 - acc: 0.8220 - val_loss: 1.4067 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.49317\n",
      "Epoch 7/40\n",
      "2343/2343 [==============================] - 389s 166ms/step - loss: 0.3649 - acc: 0.8813 - val_loss: 1.4470 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.49317\n",
      "Epoch 8/40\n",
      " 192/2343 [=>............................] - ETA: 4:37 - loss: 0.2214 - acc: 0.9375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8cfaceccdfb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist3 = model_final3.fit(\n",
    "    X_train,\n",
    "    y_train[:,:,1],\n",
    "    validation_data=(X_val, y_val[:,:,1]),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still predicting only the most commonly occurring class. Use something like the two cells below to add class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
    "# classWeight = dict(enumerate(classWeight))\n",
    "# model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y.argmax() for y in y_train[:,:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique([y.argmax() for y in y_train[:,:,1]]),\n",
    "                                                 [y.argmax() for y in y_train[:,:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerunning this block with new optimizer\n",
    "adam_opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final3 = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam_opt,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 425s 181ms/step - loss: 12.6556 - acc: 0.2783 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27304, saving model to resnet50_3.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 397s 169ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.27304\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 401s 171ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.27304\n",
      "Epoch 4/40\n",
      "2343/2343 [==============================] - 402s 172ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.27304\n",
      "Epoch 5/40\n",
      "2343/2343 [==============================] - 406s 173ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.27304\n",
      "Epoch 6/40\n",
      "2343/2343 [==============================] - 405s 173ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.27304\n",
      "Epoch 7/40\n",
      "2343/2343 [==============================] - 406s 173ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.27304\n",
      "Epoch 8/40\n",
      "2343/2343 [==============================] - 408s 174ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.27304\n",
      "Epoch 9/40\n",
      "2343/2343 [==============================] - 408s 174ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.27304\n",
      "Epoch 10/40\n",
      "2343/2343 [==============================] - 410s 175ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.27304\n",
      "Epoch 11/40\n",
      "2343/2343 [==============================] - 411s 175ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.27304\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist3 = model_final3.fit(\n",
    "    X_train,\n",
    "    y_train[:,:,1],\n",
    "    validation_data=(X_val, y_val[:,:,1]),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Better Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from [kaggle kernel](https://www.kaggle.com/joorarkesteijn/fast-cropping-preprocessing-and-augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_image(im):\n",
    "    # Compute the center (cx, cy) and radius of the eye\n",
    "    cy = im.shape[0]//2\n",
    "    midline = im[cy,:]\n",
    "    midline = np.where(midline>midline.mean()/3)[0]\n",
    "    if len(midline)>im.shape[1]//2:\n",
    "        x_start, x_end = np.min(midline), np.max(midline)\n",
    "    else: # This actually rarely happens p~1/10000\n",
    "        x_start, x_end = im.shape[1]//10, 9*im.shape[1]//10\n",
    "    cx = (x_start + x_end)/2\n",
    "    r = (x_end - x_start)/2\n",
    "    return cx, cy, r\n",
    "\n",
    "def resize_image(im, augmentation=True):\n",
    "    # Crops, resizes and potentially augments the image to IMAGE_SIZE\n",
    "    cx, cy, r = info_image(im)\n",
    "    scaling = IMAGE_SIZE/(2*r)\n",
    "    rotation = 0\n",
    "    if augmentation:\n",
    "        scaling *= 1 + 0.3 * (np.random.rand()-0.5)\n",
    "        rotation = 360 * np.random.rand()\n",
    "    M = cv2.getRotationMatrix2D((cx,cy), rotation, scaling)\n",
    "    M[0,2] -= cx - IMAGE_SIZE/2\n",
    "    M[1,2] -= cy - IMAGE_SIZE/2\n",
    "    return cv2.warpAffine(im,M,(IMAGE_SIZE,IMAGE_SIZE)) # This is the most important line\n",
    "\n",
    "def subtract_median_bg_image(im):\n",
    "    k = np.max(im.shape)//20*2+1\n",
    "    bg = cv2.medianBlur(im, k)\n",
    "    return cv2.addWeighted (im, 4, bg, -4, 128)\n",
    "\n",
    "def subtract_gaussian_bg_image(im):\n",
    "    k = np.max(im.shape)/10\n",
    "    bg = cv2.GaussianBlur(im ,(0,0) ,k)\n",
    "    return cv2.addWeighted (im, 4, bg, -4, 128)\n",
    "\n",
    "def id_to_image(id_code, resize=True, augmentation=False, subtract_gaussian=False, subtract_median=False):\n",
    "    path = '../input/train_images/{}.png'.format(id_code)\n",
    "    im = cv2.imread(path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    if resize_image:\n",
    "        im = resize_image(im, augmentation)\n",
    "    if subtract_gaussian:\n",
    "        im = subtract_gaussian_bg_image(im)\n",
    "    if subtract_median:\n",
    "        im = subtract_median_bg_image(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential option if the above yields bad results\n",
    "def RESNET_50(classes_number, optim_name='Adam', learning_rate=-1):\n",
    "    from keras.layers.core import Dense, Dropout, Flatten\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    from keras.models import Model\n",
    "\n",
    "    base_model = ResNet50(include_top=True, weights='imagenet')\n",
    "    x = base_model.layers[-2].output\n",
    "    del base_model.layers[-1:]\n",
    "    x = Dense(classes_number, activation='softmax', name='predictions')(x)\n",
    "    model = Model(input=base_model.input, output=x)\n",
    "\n",
    "    optim = get_optim('RESNET50', optim_name, learning_rate)\n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
