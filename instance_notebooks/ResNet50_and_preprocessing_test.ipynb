{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 and New Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying ResNet50 with same preprocessing as baseline simple CNN for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from keras import models, optimizers, Sequential, regularizers, layers\n",
    "from keras.models import load_model, model_from_json, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import resnet50\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Flatten, Dropout, Reshape, Dense, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import itertools\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import applications  \n",
    "from keras import backend as k\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <keras.engine.input_layer.InputLayer object at 0x7fa4a6f63780>\n",
      "1 <keras.layers.convolutional.ZeroPadding2D object at 0x7fa4a6ce0630>\n",
      "2 <keras.layers.convolutional.Conv2D object at 0x7fa4a6ce0128>\n",
      "3 <keras.layers.normalization.BatchNormalization object at 0x7fa4a6ce0278>\n",
      "4 <keras.layers.core.Activation object at 0x7fa4a6ce0f28>\n",
      "5 <keras.layers.convolutional.ZeroPadding2D object at 0x7fa4a6cfd358>\n",
      "6 <keras.layers.pooling.MaxPooling2D object at 0x7fa4a6c76f60>\n",
      "7 <keras.layers.convolutional.Conv2D object at 0x7fa4a6c79668>\n",
      "8 <keras.layers.normalization.BatchNormalization object at 0x7fa4a6b45320>\n",
      "9 <keras.layers.core.Activation object at 0x7fa4a6b453c8>\n",
      "10 <keras.layers.convolutional.Conv2D object at 0x7fa4a6b60128>\n",
      "11 <keras.layers.normalization.BatchNormalization object at 0x7fa4a6b3c048>\n",
      "12 <keras.layers.core.Activation object at 0x7fa4a6b3cf98>\n",
      "13 <keras.layers.convolutional.Conv2D object at 0x7fa4a6a7b518>\n",
      "14 <keras.layers.convolutional.Conv2D object at 0x7fa4a69d4630>\n",
      "15 <keras.layers.normalization.BatchNormalization object at 0x7fa4a69d4128>\n",
      "16 <keras.layers.normalization.BatchNormalization object at 0x7fa4a6931e48>\n",
      "17 <keras.layers.merge.Add object at 0x7fa4a68f2588>\n",
      "18 <keras.layers.core.Activation object at 0x7fa4a6836390>\n",
      "19 <keras.layers.convolutional.Conv2D object at 0x7fa4a6836a90>\n",
      "20 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5f8c6d8>\n",
      "21 <keras.layers.core.Activation object at 0x7fa4a5f027b8>\n",
      "22 <keras.layers.convolutional.Conv2D object at 0x7fa4a5ed6780>\n",
      "23 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5ea9828>\n",
      "24 <keras.layers.core.Activation object at 0x7fa4a5e4c5f8>\n",
      "25 <keras.layers.convolutional.Conv2D object at 0x7fa4a5defa90>\n",
      "26 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5d4cd30>\n",
      "27 <keras.layers.merge.Add object at 0x7fa4a5d6c7b8>\n",
      "28 <keras.layers.core.Activation object at 0x7fa4a5c46128>\n",
      "29 <keras.layers.convolutional.Conv2D object at 0x7fa4a5c6ea90>\n",
      "30 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5c11278>\n",
      "31 <keras.layers.core.Activation object at 0x7fa4a5bb0400>\n",
      "32 <keras.layers.convolutional.Conv2D object at 0x7fa4a5b4e198>\n",
      "33 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5b2eba8>\n",
      "34 <keras.layers.core.Activation object at 0x7fa4a5b2ed30>\n",
      "35 <keras.layers.convolutional.Conv2D object at 0x7fa4a5a75390>\n",
      "36 <keras.layers.normalization.BatchNormalization object at 0x7fa4a59d5e10>\n",
      "37 <keras.layers.merge.Add object at 0x7fa4a59d5cc0>\n",
      "38 <keras.layers.core.Activation object at 0x7fa4a5915240>\n",
      "39 <keras.layers.convolutional.Conv2D object at 0x7fa4a5915978>\n",
      "40 <keras.layers.normalization.BatchNormalization object at 0x7fa4a58f3630>\n",
      "41 <keras.layers.core.Activation object at 0x7fa4a5864630>\n",
      "42 <keras.layers.convolutional.Conv2D object at 0x7fa4a58365f8>\n",
      "43 <keras.layers.normalization.BatchNormalization object at 0x7fa4a57916a0>\n",
      "44 <keras.layers.core.Activation object at 0x7fa4a57b2438>\n",
      "45 <keras.layers.convolutional.Conv2D object at 0x7fa4a56d6780>\n",
      "46 <keras.layers.convolutional.Conv2D object at 0x7fa4a56acb00>\n",
      "47 <keras.layers.normalization.BatchNormalization object at 0x7fa4a56ac710>\n",
      "48 <keras.layers.normalization.BatchNormalization object at 0x7fa4a55929b0>\n",
      "49 <keras.layers.merge.Add object at 0x7fa4a5550d68>\n",
      "50 <keras.layers.core.Activation object at 0x7fa4a5497908>\n",
      "51 <keras.layers.convolutional.Conv2D object at 0x7fa4a53d94e0>\n",
      "52 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5418518>\n",
      "53 <keras.layers.core.Activation object at 0x7fa4a53ed8d0>\n",
      "54 <keras.layers.convolutional.Conv2D object at 0x7fa4a53bcbe0>\n",
      "55 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5312fd0>\n",
      "56 <keras.layers.core.Activation object at 0x7fa4a533c940>\n",
      "57 <keras.layers.convolutional.Conv2D object at 0x7fa4a525dfd0>\n",
      "58 <keras.layers.normalization.BatchNormalization object at 0x7fa4a5214ba8>\n",
      "59 <keras.layers.merge.Add object at 0x7fa4a51da400>\n",
      "60 <keras.layers.core.Activation object at 0x7fa4a511a1d0>\n",
      "61 <keras.layers.convolutional.Conv2D object at 0x7fa4a511a710>\n",
      "62 <keras.layers.normalization.BatchNormalization object at 0x7fa4a50fc588>\n",
      "63 <keras.layers.core.Activation object at 0x7fa4a5078390>\n",
      "64 <keras.layers.convolutional.Conv2D object at 0x7fa4a4fbf588>\n",
      "65 <keras.layers.normalization.BatchNormalization object at 0x7fa4a4f98438>\n",
      "66 <keras.layers.core.Activation object at 0x7fa4a4f98748>\n",
      "67 <keras.layers.convolutional.Conv2D object at 0x7fa4a4ee24e0>\n",
      "68 <keras.layers.normalization.BatchNormalization object at 0x7fa4a4ebc5f8>\n",
      "69 <keras.layers.merge.Add object at 0x7fa4a4e603c8>\n",
      "70 <keras.layers.core.Activation object at 0x7fa4a4d84668>\n",
      "71 <keras.layers.convolutional.Conv2D object at 0x7fa4a4d84d68>\n",
      "72 <keras.layers.normalization.BatchNormalization object at 0x7fa4a4d7a588>\n",
      "73 <keras.layers.core.Activation object at 0x7fa4a4cd2cf8>\n",
      "74 <keras.layers.convolutional.Conv2D object at 0x7fa4a4cbcc50>\n",
      "75 <keras.layers.normalization.BatchNormalization object at 0x7fa48b8e91d0>\n",
      "76 <keras.layers.core.Activation object at 0x7fa48b7c63c8>\n",
      "77 <keras.layers.convolutional.Conv2D object at 0x7fa48b7573c8>\n",
      "78 <keras.layers.normalization.BatchNormalization object at 0x7fa48b7bf7b8>\n",
      "79 <keras.layers.merge.Add object at 0x7fa4a6caa2e8>\n",
      "80 <keras.layers.core.Activation object at 0x7fa4a6cfc198>\n",
      "81 <keras.layers.convolutional.Conv2D object at 0x7fa4a6cfc6a0>\n",
      "82 <keras.layers.normalization.BatchNormalization object at 0x7fa4a6c8d390>\n",
      "83 <keras.layers.core.Activation object at 0x7fa4a4c1eb70>\n",
      "84 <keras.layers.convolutional.Conv2D object at 0x7fa4a498f2b0>\n",
      "85 <keras.layers.normalization.BatchNormalization object at 0x7fa4a48d37f0>\n",
      "86 <keras.layers.core.Activation object at 0x7fa4a4912a90>\n",
      "87 <keras.layers.convolutional.Conv2D object at 0x7fa4a48a2ba8>\n",
      "88 <keras.layers.convolutional.Conv2D object at 0x7fa4a482bf98>\n",
      "89 <keras.layers.normalization.BatchNormalization object at 0x7fa4a4878400>\n",
      "90 <keras.layers.normalization.BatchNormalization object at 0x7fa48a617940>\n",
      "91 <keras.layers.merge.Add object at 0x7fa48a5d75c0>\n",
      "92 <keras.layers.core.Activation object at 0x7fa48a538588>\n",
      "93 <keras.layers.convolutional.Conv2D object at 0x7fa48a538550>\n",
      "94 <keras.layers.normalization.BatchNormalization object at 0x7fa48a40b908>\n",
      "95 <keras.layers.core.Activation object at 0x7fa48a40b550>\n",
      "96 <keras.layers.convolutional.Conv2D object at 0x7fa48a3de898>\n",
      "97 <keras.layers.normalization.BatchNormalization object at 0x7fa48a32bd30>\n",
      "98 <keras.layers.core.Activation object at 0x7fa48a3114e0>\n",
      "99 <keras.layers.convolutional.Conv2D object at 0x7fa48a2f6c88>\n",
      "100 <keras.layers.normalization.BatchNormalization object at 0x7fa48a1f40f0>\n",
      "101 <keras.layers.merge.Add object at 0x7fa48a1959e8>\n",
      "102 <keras.layers.core.Activation object at 0x7fa48a1b1470>\n",
      "103 <keras.layers.convolutional.Conv2D object at 0x7fa48a1b15c0>\n",
      "104 <keras.layers.normalization.BatchNormalization object at 0x7fa48a085908>\n",
      "105 <keras.layers.core.Activation object at 0x7fa48a085550>\n",
      "106 <keras.layers.convolutional.Conv2D object at 0x7fa48a059ba8>\n",
      "107 <keras.layers.normalization.BatchNormalization object at 0x7fa48a02d668>\n",
      "108 <keras.layers.core.Activation object at 0x7fa489f8d588>\n",
      "109 <keras.layers.convolutional.Conv2D object at 0x7fa489f72b38>\n",
      "110 <keras.layers.normalization.BatchNormalization object at 0x7fa489e6e0f0>\n",
      "111 <keras.layers.merge.Add object at 0x7fa489ea8860>\n",
      "112 <keras.layers.core.Activation object at 0x7fa489e2d198>\n",
      "113 <keras.layers.convolutional.Conv2D object at 0x7fa489e2d588>\n",
      "114 <keras.layers.normalization.BatchNormalization object at 0x7fa489dbc8d0>\n",
      "115 <keras.layers.core.Activation object at 0x7fa489cfff98>\n",
      "116 <keras.layers.convolutional.Conv2D object at 0x7fa489cd3828>\n",
      "117 <keras.layers.normalization.BatchNormalization object at 0x7fa489ca9630>\n",
      "118 <keras.layers.core.Activation object at 0x7fa489c06518>\n",
      "119 <keras.layers.convolutional.Conv2D object at 0x7fa489b49a90>\n",
      "120 <keras.layers.normalization.BatchNormalization object at 0x7fa489abefd0>\n",
      "121 <keras.layers.merge.Add object at 0x7fa489b6e940>\n",
      "122 <keras.layers.core.Activation object at 0x7fa489aa6160>\n",
      "123 <keras.layers.convolutional.Conv2D object at 0x7fa489aa6550>\n",
      "124 <keras.layers.normalization.BatchNormalization object at 0x7fa489a3b898>\n",
      "125 <keras.layers.core.Activation object at 0x7fa48997fc88>\n",
      "126 <keras.layers.convolutional.Conv2D object at 0x7fa4899517f0>\n",
      "127 <keras.layers.normalization.BatchNormalization object at 0x7fa4899235c0>\n",
      "128 <keras.layers.core.Activation object at 0x7fa4898844e0>\n",
      "129 <keras.layers.convolutional.Conv2D object at 0x7fa4897c5a90>\n",
      "130 <keras.layers.normalization.BatchNormalization object at 0x7fa4897bbf98>\n",
      "131 <keras.layers.merge.Add object at 0x7fa4897e6940>\n",
      "132 <keras.layers.core.Activation object at 0x7fa489723400>\n",
      "133 <keras.layers.convolutional.Conv2D object at 0x7fa489723588>\n",
      "134 <keras.layers.normalization.BatchNormalization object at 0x7fa488632860>\n",
      "135 <keras.layers.core.Activation object at 0x7fa4886324a8>\n",
      "136 <keras.layers.convolutional.Conv2D object at 0x7fa488588780>\n",
      "137 <keras.layers.normalization.BatchNormalization object at 0x7fa4884bc4e0>\n",
      "138 <keras.layers.core.Activation object at 0x7fa4884fb6a0>\n",
      "139 <keras.layers.convolutional.Conv2D object at 0x7fa4883ffa58>\n",
      "140 <keras.layers.normalization.BatchNormalization object at 0x7fa4883f5f98>\n",
      "141 <keras.layers.merge.Add object at 0x7fa4884200f0>\n",
      "142 <keras.layers.core.Activation object at 0x7fa48835e358>\n",
      "143 <keras.layers.convolutional.Conv2D object at 0x7fa48835e550>\n",
      "144 <keras.layers.normalization.BatchNormalization object at 0x7fa4882af7f0>\n",
      "145 <keras.layers.core.Activation object at 0x7fa4882af438>\n",
      "146 <keras.layers.convolutional.Conv2D object at 0x7fa488202748>\n",
      "147 <keras.layers.normalization.BatchNormalization object at 0x7fa4881d5588>\n",
      "148 <keras.layers.core.Activation object at 0x7fa4881f8668>\n",
      "149 <keras.layers.convolutional.Conv2D object at 0x7fa48811dd30>\n",
      "150 <keras.layers.convolutional.Conv2D object at 0x7fa488056a58>\n",
      "151 <keras.layers.normalization.BatchNormalization object at 0x7fa48806ff28>\n",
      "152 <keras.layers.normalization.BatchNormalization object at 0x7fa483fb82b0>\n",
      "153 <keras.layers.merge.Add object at 0x7fa483f7e1d0>\n",
      "154 <keras.layers.core.Activation object at 0x7fa483e412b0>\n",
      "155 <keras.layers.convolutional.Conv2D object at 0x7fa483e419e8>\n",
      "156 <keras.layers.normalization.BatchNormalization object at 0x7fa483d92cc0>\n",
      "157 <keras.layers.core.Activation object at 0x7fa483d92d68>\n",
      "158 <keras.layers.convolutional.Conv2D object at 0x7fa483d65e10>\n",
      "159 <keras.layers.normalization.BatchNormalization object at 0x7fa483c909e8>\n",
      "160 <keras.layers.core.Activation object at 0x7fa483cddb70>\n",
      "161 <keras.layers.convolutional.Conv2D object at 0x7fa483c1f240>\n",
      "162 <keras.layers.normalization.BatchNormalization object at 0x7fa483b71550>\n",
      "163 <keras.layers.merge.Add object at 0x7fa483bafbe0>\n",
      "164 <keras.layers.core.Activation object at 0x7fa483b3f390>\n",
      "165 <keras.layers.convolutional.Conv2D object at 0x7fa483abe0f0>\n",
      "166 <keras.layers.normalization.BatchNormalization object at 0x7fa483a4af60>\n",
      "167 <keras.layers.core.Activation object at 0x7fa483a0ed30>\n",
      "168 <keras.layers.convolutional.Conv2D object at 0x7fa4839dbdd8>\n",
      "169 <keras.layers.normalization.BatchNormalization object at 0x7fa4838d8240>\n",
      "170 <keras.layers.core.Activation object at 0x7fa4839129b0>\n",
      "171 <keras.layers.convolutional.Conv2D object at 0x7fa483899208>\n",
      "172 <keras.layers.normalization.BatchNormalization object at 0x7fa4837eb4e0>\n",
      "173 <keras.layers.merge.Add object at 0x7fa483829cc0>\n",
      "174 <keras.layers.core.Activation object at 0x7fa4837ba2b0>\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/train_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3662 images belonging to 5 classes.\n",
      "Found 2931 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size=(224, 224)\n",
    "seed = 123\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "directory = 'data/train_images/'\n",
    "\n",
    "# set up data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "#     shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    fill_mode=\"nearest\",\n",
    "    zoom_range=0.1,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "    rotation_range=45)\n",
    "\n",
    "# create a set of images to fit the generator on for featurewise_center\n",
    "fit_images = ImageDataGenerator(rescale=1./255,\n",
    "#     shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.1,\n",
    "#     width_shift_range = 0.2,\n",
    "#     height_shift_range=0.2,\n",
    "    rotation_range=45).flow_from_directory( \n",
    "            directory, \n",
    "            target_size = target_size, \n",
    "            batch_size = 1000, # the featurewise_center will be based off 1000 images \n",
    "            seed = 123)\n",
    "\n",
    "fit_images, fit_labels = next(fit_images)\n",
    "\n",
    "train_datagen.fit(fit_images,\n",
    "                 seed = 123,\n",
    "                 augment = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all = ImageDataGenerator(rescale=1./255).flow_from_directory( \n",
    "#         directory, \n",
    "#         target_size=(224, 224), \n",
    "#         batch_size = 3662, \n",
    "#         seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_model, X_test, y_model, y_test = train_test_split(images, labels, test_size=0.20, random_state=123, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_model, y_model, test_size=0.20, random_state=123, stratify = y_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 56, 56, 256)  0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 56, 56, 256)  0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 56, 56, 256)  0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_52 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 28, 28, 512)  0           add_52[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 28, 28, 512)  0           add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 28, 28, 512)  0           add_54[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 28, 28, 512)  0           add_55[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 14, 14, 1024) 0           add_56[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 14, 14, 1024) 0           add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 14, 14, 1024) 0           add_58[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 14, 14, 1024) 0           add_59[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 14, 14, 1024) 0           add_60[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_61 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 14, 14, 1024) 0           add_61[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_62 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 7, 7, 2048)   0           add_62[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_63 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 7, 7, 2048)   0           add_63[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 7, 7, 2048)   0           add_64[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_8 False\n",
      "1 conv1_pad False\n",
      "2 conv1 False\n",
      "3 bn_conv1 False\n",
      "4 activation_148 False\n",
      "5 pool1_pad False\n",
      "6 max_pooling2d_4 False\n",
      "7 res2a_branch2a False\n",
      "8 bn2a_branch2a False\n",
      "9 activation_149 False\n",
      "10 res2a_branch2b False\n",
      "11 bn2a_branch2b False\n",
      "12 activation_150 False\n",
      "13 res2a_branch2c False\n",
      "14 res2a_branch1 False\n",
      "15 bn2a_branch2c False\n",
      "16 bn2a_branch1 False\n",
      "17 add_49 False\n",
      "18 activation_151 False\n",
      "19 res2b_branch2a False\n",
      "20 bn2b_branch2a False\n",
      "21 activation_152 False\n",
      "22 res2b_branch2b False\n",
      "23 bn2b_branch2b False\n",
      "24 activation_153 False\n",
      "25 res2b_branch2c False\n",
      "26 bn2b_branch2c False\n",
      "27 add_50 False\n",
      "28 activation_154 False\n",
      "29 res2c_branch2a False\n",
      "30 bn2c_branch2a False\n",
      "31 activation_155 False\n",
      "32 res2c_branch2b False\n",
      "33 bn2c_branch2b False\n",
      "34 activation_156 False\n",
      "35 res2c_branch2c False\n",
      "36 bn2c_branch2c False\n",
      "37 add_51 False\n",
      "38 activation_157 False\n",
      "39 res3a_branch2a False\n",
      "40 bn3a_branch2a False\n",
      "41 activation_158 False\n",
      "42 res3a_branch2b False\n",
      "43 bn3a_branch2b False\n",
      "44 activation_159 False\n",
      "45 res3a_branch2c False\n",
      "46 res3a_branch1 False\n",
      "47 bn3a_branch2c False\n",
      "48 bn3a_branch1 False\n",
      "49 add_52 False\n",
      "50 activation_160 False\n",
      "51 res3b_branch2a False\n",
      "52 bn3b_branch2a False\n",
      "53 activation_161 False\n",
      "54 res3b_branch2b False\n",
      "55 bn3b_branch2b False\n",
      "56 activation_162 False\n",
      "57 res3b_branch2c False\n",
      "58 bn3b_branch2c False\n",
      "59 add_53 False\n",
      "60 activation_163 False\n",
      "61 res3c_branch2a False\n",
      "62 bn3c_branch2a False\n",
      "63 activation_164 False\n",
      "64 res3c_branch2b False\n",
      "65 bn3c_branch2b False\n",
      "66 activation_165 False\n",
      "67 res3c_branch2c False\n",
      "68 bn3c_branch2c False\n",
      "69 add_54 False\n",
      "70 activation_166 False\n",
      "71 res3d_branch2a False\n",
      "72 bn3d_branch2a False\n",
      "73 activation_167 False\n",
      "74 res3d_branch2b False\n",
      "75 bn3d_branch2b False\n",
      "76 activation_168 False\n",
      "77 res3d_branch2c False\n",
      "78 bn3d_branch2c False\n",
      "79 add_55 False\n",
      "80 activation_169 False\n",
      "81 res4a_branch2a False\n",
      "82 bn4a_branch2a False\n",
      "83 activation_170 False\n",
      "84 res4a_branch2b False\n",
      "85 bn4a_branch2b False\n",
      "86 activation_171 False\n",
      "87 res4a_branch2c False\n",
      "88 res4a_branch1 False\n",
      "89 bn4a_branch2c False\n",
      "90 bn4a_branch1 False\n",
      "91 add_56 False\n",
      "92 activation_172 False\n",
      "93 res4b_branch2a False\n",
      "94 bn4b_branch2a False\n",
      "95 activation_173 False\n",
      "96 res4b_branch2b False\n",
      "97 bn4b_branch2b False\n",
      "98 activation_174 False\n",
      "99 res4b_branch2c False\n",
      "100 bn4b_branch2c False\n",
      "101 add_57 False\n",
      "102 activation_175 False\n",
      "103 res4c_branch2a False\n",
      "104 bn4c_branch2a False\n",
      "105 activation_176 False\n",
      "106 res4c_branch2b False\n",
      "107 bn4c_branch2b False\n",
      "108 activation_177 False\n",
      "109 res4c_branch2c False\n",
      "110 bn4c_branch2c False\n",
      "111 add_58 False\n",
      "112 activation_178 False\n",
      "113 res4d_branch2a False\n",
      "114 bn4d_branch2a False\n",
      "115 activation_179 False\n",
      "116 res4d_branch2b False\n",
      "117 bn4d_branch2b False\n",
      "118 activation_180 False\n",
      "119 res4d_branch2c False\n",
      "120 bn4d_branch2c False\n",
      "121 add_59 False\n",
      "122 activation_181 False\n",
      "123 res4e_branch2a False\n",
      "124 bn4e_branch2a False\n",
      "125 activation_182 False\n",
      "126 res4e_branch2b False\n",
      "127 bn4e_branch2b False\n",
      "128 activation_183 False\n",
      "129 res4e_branch2c False\n",
      "130 bn4e_branch2c False\n",
      "131 add_60 False\n",
      "132 activation_184 False\n",
      "133 res4f_branch2a False\n",
      "134 bn4f_branch2a False\n",
      "135 activation_185 False\n",
      "136 res4f_branch2b False\n",
      "137 bn4f_branch2b False\n",
      "138 activation_186 False\n",
      "139 res4f_branch2c False\n",
      "140 bn4f_branch2c False\n",
      "141 add_61 False\n",
      "142 activation_187 False\n",
      "143 res5a_branch2a False\n",
      "144 bn5a_branch2a False\n",
      "145 activation_188 False\n",
      "146 res5a_branch2b False\n",
      "147 bn5a_branch2b False\n",
      "148 activation_189 False\n",
      "149 res5a_branch2c False\n",
      "150 res5a_branch1 False\n",
      "151 bn5a_branch2c False\n",
      "152 bn5a_branch1 False\n",
      "153 add_62 False\n",
      "154 activation_190 False\n",
      "155 res5b_branch2a False\n",
      "156 bn5b_branch2a False\n",
      "157 activation_191 False\n",
      "158 res5b_branch2b False\n",
      "159 bn5b_branch2b False\n",
      "160 activation_192 False\n",
      "161 res5b_branch2c False\n",
      "162 bn5b_branch2c False\n",
      "163 add_63 False\n",
      "164 activation_193 False\n",
      "165 res5c_branch2a False\n",
      "166 bn5c_branch2a False\n",
      "167 activation_194 False\n",
      "168 res5c_branch2b False\n",
      "169 bn5c_branch2b False\n",
      "170 activation_195 False\n",
      "171 res5c_branch2c False\n",
      "172 bn5c_branch2c False\n",
      "173 add_64 False\n",
      "174 activation_196 False\n",
      "175 flatten_4 True\n",
      "176 dense_9 True\n",
      "177 dropout_3 True\n",
      "178 dense_10 True\n",
      "179 dense_11 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 622s 14s/step - loss: 1.6402 - acc: 0.6167 - val_loss: 1.3876 - val_acc: 0.4986\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49858, saving model to resnet50_1.h5\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 522s 12s/step - loss: 0.7861 - acc: 0.7156 - val_loss: 1.4654 - val_acc: 0.4918\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49858\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 526s 12s/step - loss: 0.7618 - acc: 0.7231 - val_loss: 1.5097 - val_acc: 0.4903\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49858\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 536s 12s/step - loss: 0.7028 - acc: 0.7378 - val_loss: 1.3776 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.49858 to 0.49925, saving model to resnet50_1.h5\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 530s 12s/step - loss: 0.6681 - acc: 0.7532 - val_loss: 1.4772 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49925\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 527s 12s/step - loss: 0.6664 - acc: 0.7445 - val_loss: 1.5434 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.49925\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 531s 12s/step - loss: 0.6515 - acc: 0.7560 - val_loss: 1.4919 - val_acc: 0.5097\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.49925 to 0.50975, saving model to resnet50_1.h5\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 529s 12s/step - loss: 0.6245 - acc: 0.7627 - val_loss: 1.5997 - val_acc: 0.4828\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50975\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 533s 12s/step - loss: 0.6075 - acc: 0.7721 - val_loss: 1.6043 - val_acc: 0.4828\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50975\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 543s 12s/step - loss: 0.6023 - acc: 0.7792 - val_loss: 1.5905 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50975\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 528s 12s/step - loss: 0.6025 - acc: 0.7713 - val_loss: 1.5225 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.50975\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 532s 12s/step - loss: 0.6013 - acc: 0.7782 - val_loss: 1.6276 - val_acc: 0.4858\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.50975\n",
      "Epoch 13/50\n",
      "44/45 [============================>.] - ETA: 9s - loss: 0.5497 - acc: 0.7883 "
     ]
    }
   ],
   "source": [
    "model_hist = model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "             normalize=False,\n",
    "             title='Confusion matrix',\n",
    "             cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \n",
    "#     print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_ = confusion_matrix(y_test.argmax(axis = 1), model_final.predict(X_test).argmax(axis=1))\n",
    "classes_ = ['0','1','2','3','4']\n",
    "plot_confusion_matrix(cm_, classes = classes_, normalize=False,\n",
    "                      title='Non-normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        59\n",
      "           1       0.00      0.00      0.00        74\n",
      "           2       0.00      0.00      0.00        39\n",
      "           3       0.00      0.00      0.00       200\n",
      "           4       0.49      1.00      0.66       361\n",
      "\n",
      "   micro avg       0.49      0.49      0.49       733\n",
      "   macro avg       0.10      0.20      0.13       733\n",
      "weighted avg       0.24      0.49      0.33       733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1),model_final.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "#saving the model and its weights\n",
    "\n",
    "model_json = model_final.to_json()\n",
    "with open(\"model_resnet50_1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_final.save_weights(\"model_resnet50_1_weights.h5\")\n",
    "print(\"Saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Adam optimizer\n",
    "\n",
    "Forgot to enter the validation data during the first fitting. After entering the validation data, the validation accuracy remained constant throughout fitting. Going to try Adam optimizer below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final2 = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 408s 174ms/step - loss: 5.8480 - acc: 0.6206 - val_loss: 8.1691 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49317, saving model to resnet50_2.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 400s 171ms/step - loss: 4.9151 - acc: 0.6944 - val_loss: 8.1691 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49317\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 396s 169ms/step - loss: 5.5478 - acc: 0.6551 - val_loss: 8.1691 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49317\n",
      "Epoch 4/40\n",
      " 128/2343 [>.............................] - ETA: 5:02 - loss: 4.5332 - acc: 0.7188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dab389b7378d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist2 = model_final2.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using to_categorical\n",
    "\n",
    "The validation accuracy has been stuck at 0.49317 because it's just predicting the most frequently occurring class every time. One answer after some googling suggests that using to_categorical may fix this, as the problem could be originating from an error in comparing against the y matrices.\n",
    "\n",
    "Although, if the above is true, why is the training accuracy changing? It should be categorical already...\n",
    "\n",
    "Use weights for balancing the target classes if this doesn't fix the stuck accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final3 = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 392s 167ms/step - loss: 9.8712 - acc: 0.3453 - val_loss: 3.9761 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49317, saving model to resnet50_3.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 391s 167ms/step - loss: 4.2093 - acc: 0.7247 - val_loss: 3.4970 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49317\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 389s 166ms/step - loss: 4.0529 - acc: 0.7358 - val_loss: 3.2725 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49317\n",
      "Epoch 4/40\n",
      "2343/2343 [==============================] - 387s 165ms/step - loss: 2.7864 - acc: 0.7187 - val_loss: 1.9380 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.49317\n",
      "Epoch 5/40\n",
      "2343/2343 [==============================] - 387s 165ms/step - loss: 0.8128 - acc: 0.7550 - val_loss: 1.4317 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49317\n",
      "Epoch 6/40\n",
      "2343/2343 [==============================] - 390s 166ms/step - loss: 0.5152 - acc: 0.8220 - val_loss: 1.4067 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.49317\n",
      "Epoch 7/40\n",
      "2343/2343 [==============================] - 389s 166ms/step - loss: 0.3649 - acc: 0.8813 - val_loss: 1.4470 - val_acc: 0.4932\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.49317\n",
      "Epoch 8/40\n",
      " 192/2343 [=>............................] - ETA: 4:37 - loss: 0.2214 - acc: 0.9375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-8cfaceccdfb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist3 = model_final3.fit(\n",
    "    X_train,\n",
    "    y_train[:,:,1],\n",
    "    validation_data=(X_val, y_val[:,:,1]),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still predicting only the most commonly occurring class. Use something like the two cells below to add class weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classWeight = compute_class_weight('balanced', outputLabels, outputs) \n",
    "# classWeight = dict(enumerate(classWeight))\n",
    "# model.fit(X_train, y_train, batch_size = batch_size, nb_epoch = nb_epochs, show_accuracy = True, verbose = 2, validation_data = (X_test, y_test), class_weight=classWeight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val) \n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y.argmax() for y in y_train[:,:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique([y.argmax() for y in y_train[:,:,1]]),\n",
    "                                                 [y.argmax() for y in y_train[:,:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 224, 224\n",
    "img_shape = (img_width, img_height, 3)\n",
    "img_input = Input(shape=img_shape)\n",
    "base_model = resnet50.ResNet50(include_top=False, weights='imagenet', input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerunning this block with new optimizer\n",
    "adam_opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:175]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final3 = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final3.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam_opt,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2343 samples, validate on 586 samples\n",
      "Epoch 1/40\n",
      "2343/2343 [==============================] - 425s 181ms/step - loss: 12.6556 - acc: 0.2783 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27304, saving model to resnet50_3.h5\n",
      "Epoch 2/40\n",
      "2343/2343 [==============================] - 397s 169ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.27304\n",
      "Epoch 3/40\n",
      "2343/2343 [==============================] - 401s 171ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.27304\n",
      "Epoch 4/40\n",
      "2343/2343 [==============================] - 402s 172ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.27304\n",
      "Epoch 5/40\n",
      "2343/2343 [==============================] - 406s 173ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.27304\n",
      "Epoch 6/40\n",
      "2343/2343 [==============================] - 405s 173ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.27304\n",
      "Epoch 7/40\n",
      "2343/2343 [==============================] - 406s 173ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.27304\n",
      "Epoch 8/40\n",
      "2343/2343 [==============================] - 408s 174ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.27304\n",
      "Epoch 9/40\n",
      "2343/2343 [==============================] - 408s 174ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.27304\n",
      "Epoch 10/40\n",
      "2343/2343 [==============================] - 410s 175ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.27304\n",
      "Epoch 11/40\n",
      "2343/2343 [==============================] - 411s 175ms/step - loss: 12.8945 - acc: 0.2727 - val_loss: 11.7173 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.27304\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist3 = model_final3.fit(\n",
    "    X_train,\n",
    "    y_train[:,:,1],\n",
    "    validation_data=(X_val, y_val[:,:,1]),\n",
    "    epochs = 40,\n",
    "    batch_size = 64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Better Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from [kaggle kernel](https://www.kaggle.com/joorarkesteijn/fast-cropping-preprocessing-and-augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_image(im):\n",
    "    # Compute the center (cx, cy) and radius of the eye\n",
    "    cy = im.shape[0]//2\n",
    "    midline = im[cy,:]\n",
    "    midline = np.where(midline>midline.mean()/3)[0]\n",
    "    if len(midline)>im.shape[1]//2:\n",
    "        x_start, x_end = np.min(midline), np.max(midline)\n",
    "    else: # This actually rarely happens p~1/10000\n",
    "        x_start, x_end = im.shape[1]//10, 9*im.shape[1]//10\n",
    "    cx = (x_start + x_end)/2\n",
    "    r = (x_end - x_start)/2\n",
    "    return cx, cy, r\n",
    "\n",
    "def resize_image(im, augmentation=True):\n",
    "    # Crops, resizes and potentially augments the image to IMAGE_SIZE\n",
    "    cx, cy, r = info_image(im)\n",
    "    scaling = IMAGE_SIZE/(2*r)\n",
    "    rotation = 0\n",
    "    if augmentation:\n",
    "        scaling *= 1 + 0.3 * (np.random.rand()-0.5)\n",
    "        rotation = 360 * np.random.rand()\n",
    "    M = cv2.getRotationMatrix2D((cx,cy), rotation, scaling)\n",
    "    M[0,2] -= cx - IMAGE_SIZE/2\n",
    "    M[1,2] -= cy - IMAGE_SIZE/2\n",
    "    return cv2.warpAffine(im,M,(IMAGE_SIZE,IMAGE_SIZE)) # This is the most important line\n",
    "\n",
    "def subtract_median_bg_image(im):\n",
    "    k = np.max(im.shape)//20*2+1\n",
    "    bg = cv2.medianBlur(im, k)\n",
    "    return cv2.addWeighted (im, 4, bg, -4, 128)\n",
    "\n",
    "def subtract_gaussian_bg_image(im):\n",
    "    k = np.max(im.shape)/10\n",
    "    bg = cv2.GaussianBlur(im ,(0,0) ,k)\n",
    "    return cv2.addWeighted (im, 4, bg, -4, 128)\n",
    "\n",
    "def id_to_image(id_code, resize=True, augmentation=False, subtract_gaussian=False, subtract_median=False):\n",
    "    path = '../input/train_images/{}.png'.format(id_code)\n",
    "    im = cv2.imread(path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    if resize_image:\n",
    "        im = resize_image(im, augmentation)\n",
    "    if subtract_gaussian:\n",
    "        im = subtract_gaussian_bg_image(im)\n",
    "    if subtract_median:\n",
    "        im = subtract_median_bg_image(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# potential option if the above yields bad results\n",
    "def RESNET_50(classes_number, optim_name='Adam', learning_rate=-1):\n",
    "    from keras.layers.core import Dense, Dropout, Flatten\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    from keras.models import Model\n",
    "\n",
    "    base_model = ResNet50(include_top=True, weights='imagenet')\n",
    "    x = base_model.layers[-2].output\n",
    "    del base_model.layers[-1:]\n",
    "    x = Dense(classes_number, activation='softmax', name='predictions')(x)\n",
    "    model = Model(input=base_model.input, output=x)\n",
    "\n",
    "    optim = get_optim('RESNET50', optim_name, learning_rate)\n",
    "    model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
