{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-19 First Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6 False\n",
      "1 block1_conv1 True\n",
      "2 block1_conv2 True\n",
      "3 block1_pool True\n",
      "4 block2_conv1 True\n",
      "5 block2_conv2 True\n",
      "6 block2_pool True\n",
      "7 block3_conv1 True\n",
      "8 block3_conv2 True\n",
      "9 block3_conv3 True\n",
      "10 block3_conv4 True\n",
      "11 block3_pool True\n",
      "12 block4_conv1 True\n",
      "13 block4_conv2 True\n",
      "14 block4_conv3 True\n",
      "15 block4_conv4 True\n",
      "16 block4_pool True\n",
      "17 block5_conv1 True\n",
      "18 block5_conv2 True\n",
      "19 block5_conv3 True\n",
      "20 block5_conv4 True\n",
      "21 block5_pool True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers[:22]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_conv4 False\n",
      "11 block3_pool False\n",
      "12 block4_conv1 False\n",
      "13 block4_conv2 False\n",
      "14 block4_conv3 False\n",
      "15 block4_conv4 False\n",
      "16 block4_pool False\n",
      "17 block5_conv1 False\n",
      "18 block5_conv2 False\n",
      "19 block5_conv3 False\n",
      "20 block5_conv4 False\n",
      "21 block5_pool False\n",
      "22 flatten_5 True\n",
      "23 dense_17 True\n",
      "24 dropout_5 True\n",
      "25 dense_18 True\n",
      "26 dense_19 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2931 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size=(224, 224) # change to (img_width, img_height) since it's already set at in the first cell of the notebook\n",
    "seed = 123\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "directory = 'data/train_images/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidentally saved the weights as vgg16_1.h5 instead of vgg19_1.h5\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 1331s 15s/step - loss: 1.4197 - acc: 0.4839 - val_loss: 1.1443 - val_acc: 0.5270\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.52699, saving model to vgg16_1.h5\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 1.2026 - acc: 0.5258 - val_loss: 1.1441 - val_acc: 0.5708\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.52699 to 0.57082, saving model to vgg16_1.h5\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 1301s 14s/step - loss: 1.1288 - acc: 0.5621 - val_loss: 1.0179 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.57082 to 0.61516, saving model to vgg16_1.h5\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 1299s 14s/step - loss: 1.1045 - acc: 0.5883 - val_loss: 1.0738 - val_acc: 0.5823\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.61516\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 1300s 14s/step - loss: 1.0738 - acc: 0.5985 - val_loss: 1.0131 - val_acc: 0.6180\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.61516 to 0.61803, saving model to vgg16_1.h5\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 1302s 14s/step - loss: 1.0756 - acc: 0.6063 - val_loss: 1.0481 - val_acc: 0.6023\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.61803\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 1301s 14s/step - loss: 1.0651 - acc: 0.6179 - val_loss: 1.0329 - val_acc: 0.6395\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61803 to 0.63948, saving model to vgg16_1.h5\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 1304s 14s/step - loss: 1.0364 - acc: 0.6191 - val_loss: 0.9683 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.63948 to 0.65093, saving model to vgg16_1.h5\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 1306s 14s/step - loss: 1.0182 - acc: 0.6325 - val_loss: 0.9252 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.65093 to 0.65236, saving model to vgg16_1.h5\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 1305s 14s/step - loss: 1.0593 - acc: 0.6195 - val_loss: 0.9969 - val_acc: 0.6423\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.65236\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 1306s 14s/step - loss: 1.0114 - acc: 0.6354 - val_loss: 0.9303 - val_acc: 0.6624\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.65236 to 0.66237, saving model to vgg16_1.h5\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 1309s 14s/step - loss: 1.0093 - acc: 0.6394 - val_loss: 0.9191 - val_acc: 0.6266\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.66237\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 1.0080 - acc: 0.6372 - val_loss: 0.9592 - val_acc: 0.6552\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.66237\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 1316s 14s/step - loss: 1.0159 - acc: 0.6364 - val_loss: 1.1505 - val_acc: 0.5765\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.66237\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 1308s 14s/step - loss: 0.9819 - acc: 0.6461 - val_loss: 0.9872 - val_acc: 0.6137\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.66237\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 1308s 14s/step - loss: 0.9844 - acc: 0.6370 - val_loss: 0.9172 - val_acc: 0.6567\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.66237\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 1307s 14s/step - loss: 0.9957 - acc: 0.6376 - val_loss: 0.9186 - val_acc: 0.6423\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.66237\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9711 - acc: 0.6583 - val_loss: 0.8703 - val_acc: 0.6795\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.66237 to 0.67954, saving model to vgg16_1.h5\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 1308s 14s/step - loss: 0.9693 - acc: 0.6575 - val_loss: 0.9200 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.67954\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 1307s 14s/step - loss: 0.9805 - acc: 0.6525 - val_loss: 0.9528 - val_acc: 0.6581\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.67954\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 1308s 14s/step - loss: 0.9687 - acc: 0.6616 - val_loss: 0.9600 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.67954\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 1307s 14s/step - loss: 0.9498 - acc: 0.6586 - val_loss: 0.9141 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.67954\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 1307s 14s/step - loss: 0.9631 - acc: 0.6586 - val_loss: 0.8958 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.67954\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9844 - acc: 0.6516 - val_loss: 0.9191 - val_acc: 0.6605\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.67954\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 1307s 14s/step - loss: 0.9644 - acc: 0.6525 - val_loss: 0.9064 - val_acc: 0.6767\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.67954\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 1311s 14s/step - loss: 0.9615 - acc: 0.6605 - val_loss: 0.9321 - val_acc: 0.6681\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.67954\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9511 - acc: 0.6713 - val_loss: 0.9259 - val_acc: 0.6810\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.67954 to 0.68097, saving model to vgg16_1.h5\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 1308s 14s/step - loss: 0.9436 - acc: 0.6582 - val_loss: 0.9612 - val_acc: 0.6366\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.68097\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 1309s 14s/step - loss: 0.9445 - acc: 0.6753 - val_loss: 0.9019 - val_acc: 0.6595\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.68097\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 1308s 14s/step - loss: 0.9608 - acc: 0.6539 - val_loss: 0.9375 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.68097\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 1309s 14s/step - loss: 0.9189 - acc: 0.6748 - val_loss: 0.8621 - val_acc: 0.7039\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.68097 to 0.70386, saving model to vgg16_1.h5\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 1311s 14s/step - loss: 0.9359 - acc: 0.6716 - val_loss: 0.9102 - val_acc: 0.6896\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.70386\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9510 - acc: 0.6701 - val_loss: 0.9235 - val_acc: 0.6466\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.70386\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9348 - acc: 0.6756 - val_loss: 0.8839 - val_acc: 0.6495\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.70386\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9621 - acc: 0.6646 - val_loss: 0.9280 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.70386\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9229 - acc: 0.6831 - val_loss: 0.8985 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.70386\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9363 - acc: 0.6625 - val_loss: 0.9367 - val_acc: 0.6738\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.70386\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 1311s 14s/step - loss: 0.8973 - acc: 0.6919 - val_loss: 0.8494 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.70386\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 1310s 14s/step - loss: 0.9308 - acc: 0.6744 - val_loss: 0.8781 - val_acc: 0.6781\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.70386\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 1314s 14s/step - loss: 0.9177 - acc: 0.6829 - val_loss: 0.9106 - val_acc: 0.6524\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.70386\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 1313s 14s/step - loss: 0.9109 - acc: 0.6797 - val_loss: 0.9118 - val_acc: 0.6781\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.70386\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist = model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfreezing all layers and continuing training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidentally saved the weights as vgg16_1.h5 instead of vgg19_1.h5 on first model. Continuing with vgg19_2.h5\n",
    "checkpoint = ModelCheckpoint(\"vgg19_2.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv2 False\n",
      "3 block1_pool False\n",
      "4 block2_conv1 False\n",
      "5 block2_conv2 False\n",
      "6 block2_pool False\n",
      "7 block3_conv1 False\n",
      "8 block3_conv2 False\n",
      "9 block3_conv3 False\n",
      "10 block3_conv4 False\n",
      "11 block3_pool False\n",
      "12 block4_conv1 False\n",
      "13 block4_conv2 False\n",
      "14 block4_conv3 False\n",
      "15 block4_conv4 False\n",
      "16 block4_pool False\n",
      "17 block5_conv1 False\n",
      "18 block5_conv2 False\n",
      "19 block5_conv3 False\n",
      "20 block5_conv4 False\n",
      "21 block5_pool False\n",
      "22 flatten_5 True\n",
      "23 dense_17 True\n",
      "24 dropout_5 True\n",
      "25 dense_18 True\n",
      "26 dense_19 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6 True\n",
      "1 block1_conv1 True\n",
      "2 block1_conv2 True\n",
      "3 block1_pool True\n",
      "4 block2_conv1 True\n",
      "5 block2_conv2 True\n",
      "6 block2_pool True\n",
      "7 block3_conv1 True\n",
      "8 block3_conv2 True\n",
      "9 block3_conv3 True\n",
      "10 block3_conv4 True\n",
      "11 block3_pool True\n",
      "12 block4_conv1 True\n",
      "13 block4_conv2 True\n",
      "14 block4_conv3 True\n",
      "15 block4_conv4 True\n",
      "16 block4_pool True\n",
      "17 block5_conv1 True\n",
      "18 block5_conv2 True\n",
      "19 block5_conv3 True\n",
      "20 block5_conv4 True\n",
      "21 block5_pool True\n",
      "22 flatten_5 True\n",
      "23 dense_17 True\n",
      "24 dropout_5 True\n",
      "25 dense_18 True\n",
      "26 dense_19 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change generator to gapcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gapcv\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/57/46b0539ace5d2b7f7c1ce2c24a37c8603ea9624462e815d26d191388eed1/gapcv-1.0.0.tar.gz\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from gapcv) (1.16.3)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from gapcv) (2.9.0)\n",
      "Collecting imutils (from gapcv)\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gapcv) (2.21.0)\n",
      "Collecting opencv-python (from gapcv)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/52/61b9619a7a95a8d809515f68f1441224a07ce1873fd3af5e662851014a55/opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n",
      "\u001b[K     |████████████████████████████████| 26.6MB 8.5MB/s eta 0:00:01�                             | 1.8MB 8.5MB/s eta 0:00:035.0MB 8.5MB/s eta 0:00:03��███▌                      | 7.8MB 8.5MB/s eta 0:00:03.5MB/s eta 0:00:02�███████████████▎             | 15.2MB 8.5MB/s eta 0:00:02████████████████▊         | 18.8MB 8.5MB/s eta 0:00:01��█████████████████████████▏    | 22.5MB 8.5MB/s eta 0:00:01��████████▋ | 25.4MB 8.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from gapcv) (6.0.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->gapcv) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->gapcv) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->gapcv) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gapcv) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gapcv) (1.24.2)\n",
      "Building wheels for collected packages: gapcv, imutils\n",
      "  Building wheel for gapcv (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/fa/64/71/6be0efb1982b7ea259532e0db37c112d42156c06bb70ab9a2a\n",
      "  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\n",
      "Successfully built gapcv imutils\n",
      "Installing collected packages: imutils, opencv-python, gapcv\n",
      "Successfully installed gapcv-1.0.0 imutils-0.5.2 opencv-python-4.1.0.25\n"
     ]
    }
   ],
   "source": [
    "!pip install gapcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gapcv.vision import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Images('diabetic_retinopathy', directory, config=['resize=({},{})'.format(img_height, img_width), 'store', 'stream'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Images(config=['stream'])\n",
    "images.load('diabetic_retinopathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set\n",
    "images.split = 0.2\n",
    "X_test, Y_test = images.test\n",
    "\n",
    "# generator\n",
    "images.minibatch = batch_size\n",
    "gap_generator = images.minibatch\n",
    "\n",
    "total_train_images = images.count - len(X_test)\n",
    "n_classes = len(images.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(\n",
    "#     generator=gap_generator,\n",
    "#     validation_data=(X_test, Y_test),\n",
    "#     steps_per_epoch=total_train_images // batch_size,\n",
    "#     epochs=nb_epochs,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 3076s 34s/step - loss: 14.8284 - acc: 0.0800 - val_loss: 14.8207 - val_acc: 0.0805\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08049, saving model to vgg19_2.h5\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 3088s 34s/step - loss: 14.8125 - acc: 0.0810 - val_loss: 14.8207 - val_acc: 0.0805\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.08049\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 3093s 34s/step - loss: 14.8560 - acc: 0.0783 - val_loss: 14.8207 - val_acc: 0.0805\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.08049\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 3083s 34s/step - loss: 14.7896 - acc: 0.0824 - val_loss: 14.8207 - val_acc: 0.0805\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.08049\n",
      "Epoch 5/10\n",
      "20/91 [=====>........................] - ETA: 37:18 - loss: 14.8085 - acc: 0.0813"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist2 = model_final.fit_generator(\n",
    "    gap_generator,\n",
    "    steps_per_epoch = total_train_images // batch_size,\n",
    "    validation_data = (X_test, Y_test),\n",
    "#     validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/91 [..............................] - ETA: 1:05:31 - loss: 1.2555 - acc: 0.5312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-304edad8aa70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     callbacks = [checkpoint, early])\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist2 = model_final.fit_generator(\n",
    "    gap_generator,\n",
    "    steps_per_epoch = total_train_images // batch_size,\n",
    "    validation_data = (X_test, Y_test),\n",
    "#     validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "model = applications.VGG19(weights = None, include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 block1_conv1 True\n",
      "2 block1_conv2 True\n",
      "3 block1_pool True\n",
      "4 block2_conv1 True\n",
      "5 block2_conv2 True\n",
      "6 block2_pool True\n",
      "7 block3_conv1 True\n",
      "8 block3_conv2 True\n",
      "9 block3_conv3 True\n",
      "10 block3_conv4 True\n",
      "11 block3_pool True\n",
      "12 block4_conv1 True\n",
      "13 block4_conv2 True\n",
      "14 block4_conv3 True\n",
      "15 block4_conv4 True\n",
      "16 block4_pool True\n",
      "17 block5_conv1 True\n",
      "18 block5_conv2 True\n",
      "19 block5_conv3 True\n",
      "20 block5_conv4 True\n",
      "21 block5_pool True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# for layer in model.layers[:22]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "predictions = Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2 False\n",
      "1 block1_conv1 True\n",
      "2 block1_conv2 True\n",
      "3 block1_pool True\n",
      "4 block2_conv1 True\n",
      "5 block2_conv2 True\n",
      "6 block2_pool True\n",
      "7 block3_conv1 True\n",
      "8 block3_conv2 True\n",
      "9 block3_conv3 True\n",
      "10 block3_conv4 True\n",
      "11 block3_pool True\n",
      "12 block4_conv1 True\n",
      "13 block4_conv2 True\n",
      "14 block4_conv3 True\n",
      "15 block4_conv4 True\n",
      "16 block4_pool True\n",
      "17 block5_conv1 True\n",
      "18 block5_conv2 True\n",
      "19 block5_conv3 True\n",
      "20 block5_conv4 True\n",
      "21 block5_pool True\n",
      "22 flatten_2 True\n",
      "23 dense_4 True\n",
      "24 dropout_2 True\n",
      "25 dense_5 True\n",
      "26 dense_6 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2931 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "target_size=(224, 224) # change to (img_width, img_height) since it's already set at in the first cell of the notebook\n",
    "seed = 123\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "directory = 'data/train_images/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "#     shear_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "#     fill_mode = \"nearest\",\n",
    "#     zoom_range = 0.3,\n",
    "#     width_shift_range = 0.3,\n",
    "#     height_shift_range=0.3,\n",
    "#     rotation_range=30) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory, # same directory as training data\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    class_mode=\"categorical\",\n",
    "    subset='validation') # set as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'four': 0, 'one': 1, 'three': 2, 'two': 3, 'zero': 4}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidentally saved the weights as vgg16_1.h5 instead of vgg19_1.h5\n",
    "checkpoint = ModelCheckpoint(\"vgg19_no_weights_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "45/45 [==============================] - 3178s 71s/step - loss: 1.5307 - acc: 0.4830 - val_loss: 1.4340 - val_acc: 0.4986\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.49858, saving model to vgg19_no_weights_1.h5\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 3106s 69s/step - loss: 1.3558 - acc: 0.4969 - val_loss: 1.3064 - val_acc: 0.4918\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.49858\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 3103s 69s/step - loss: 1.3086 - acc: 0.4868 - val_loss: 1.3053 - val_acc: 0.4903\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.49858\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 3105s 69s/step - loss: 1.3002 - acc: 0.4925 - val_loss: 1.2894 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.49858 to 0.49925, saving model to vgg19_no_weights_1.h5\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 3105s 69s/step - loss: 1.2911 - acc: 0.4999 - val_loss: 1.2634 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.49925\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 3105s 69s/step - loss: 1.2959 - acc: 0.4905 - val_loss: 1.3192 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.49925\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 3098s 69s/step - loss: 1.2995 - acc: 0.4900 - val_loss: 1.2767 - val_acc: 0.5097\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.49925 to 0.50975, saving model to vgg19_no_weights_1.h5\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 3094s 69s/step - loss: 1.3057 - acc: 0.4926 - val_loss: 1.3193 - val_acc: 0.4828\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50975\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 3093s 69s/step - loss: 1.3026 - acc: 0.4853 - val_loss: 1.2998 - val_acc: 0.4828\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50975\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 3090s 69s/step - loss: 1.2867 - acc: 0.5045 - val_loss: 1.2764 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50975\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 3084s 69s/step - loss: 1.3042 - acc: 0.4861 - val_loss: 1.2865 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.50975\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 3092s 69s/step - loss: 1.2931 - acc: 0.4934 - val_loss: 1.2927 - val_acc: 0.4858\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.50975\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 3101s 69s/step - loss: 1.2963 - acc: 0.4938 - val_loss: 1.2890 - val_acc: 0.4957\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.50975\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 3087s 69s/step - loss: 1.2921 - acc: 0.4990 - val_loss: 1.2883 - val_acc: 0.4948\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.50975\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 3087s 69s/step - loss: 1.3013 - acc: 0.4888 - val_loss: 1.3042 - val_acc: 0.4888\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.50975\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 3085s 69s/step - loss: 1.3007 - acc: 0.4840 - val_loss: 1.2921 - val_acc: 0.4933\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.50975\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 3088s 69s/step - loss: 1.2978 - acc: 0.4963 - val_loss: 1.2839 - val_acc: 0.5037\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.50975\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_hist = model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    callbacks = [checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
